#   Copyright
#
#      Copyright (C) 2011 Dell Inc.
#
#   License
#
#       This program is free software; you can redistribute it and/or modify
#       it under the terms of the GNU General Public License as published by
#       the Free Software Foundation; either version 3 of the License, or
#       (at your option) any later version.
#
#       This program is distributed in the hope that it will be useful,
#       but WITHOUT ANY WARRANTY; without even the implied warranty of
#       MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
#       GNU General Public License for more details.
#
#       You should have received a copy of the GNU General Public License
#       along with this program. If not, see <http://www.gnu.org/licenses/>.
#
#   Description
#
#	To learn what TOP LEVEL section to use in manual pages,
#	see POSIX/Susv standard and "Utility Description Defaults" at
#	http://www.opengroup.org/onlinepubs/009695399/utilities/xcu_chap01.html#tag_01_11
#
#	This is manual page in Perl POD format. Read more at
#	http://perldoc.perl.org/perlpod.html or run command:
#
#	    perldoc perlpod | less
#
#	To check the syntax:
#
#	    podchecker *.pod
#
#	Create manual page with command:
#
#	    pod2man PAGE.N.pod > PAGE.N

=pod

=head1 NAME

zpaq - Archiver and compression algorithm development tool

=head1 SYNOPSIS

  To compress:     zpaq [-bfhijmnpqstv] {a|c} <archive> <files>...
  To extract:      zpaq [-fijnpstv] {e|x} <archive> [<files>...]
  To list:         zpaq [-v] l <archive>
  To copy blocks:  zpaq [-v] b archive output [N[-N]]
  To run config:   zpaq [-hjv] r [input [output]]
  To trace config: zpaq [-hv] t [N...]
  For quick help:  zpaq

=head1 DESCRIPTION

I<zpaq> is a program to create, extract, and list compressed archives
in ZPAQ level 1 format
and a tool for developing new compression algorithms.
The ZPAQ standard defines a flexible, self-describing,
streaming (one pass) format for storing compressed data. The compressed
format is based on the PAQ series of context-mixing and bitwise prediction
algorithms, which are top ranked by compression ratio on many benchmarks.

PAQ was developed as a series of over 160 incremental improvements
between 2000 and 2010, each of which broke compatibility with
archives compressed by other versions. ZPAQ solves this problem
by including a description of the decompression algorithm in the
archive. The ZPAQ format is described by a specification, an open
source reference decoder, and an open source C++ library API,
libzpaq(3), providing scanning, compression, and decompression services.
(See I<availability>).

I<zpaq> has 4 built in compression levels to let you
select between better speed or better compression ratio. It also
accepts custom compression algorithms described by configuration
files and optional external preprocessing programs. I<zpaq> and other
ZPAQ conforming programs such as zpipe(1) and the reference
decoder (I<unzpaq>) do not need these extra files to read the
resulting archive.

A ZPAQ stream consists of a sequence of independent blocks
with a header describing the decompression algorithm. Each
block contains segments with an optional filename, an optional
comment (showing original size), compressed data, and an optional
SHA-1 checksum.
All are stored by default, but there are options to omit them.
A segment without a filename represents data concatenated to
the previous segment.

Blocks can be split apart and reordered, which has the effect of
reordering the data they represent. If more than one processor
is available, then I<zpaq> will compress or decompress blocks
in parallel in separate threads. By default,
I<zpaq> splits large files into 16 MB blocks for parallel
compression. There are options to change the block size or
to compress whole files or the whole archive in a single block
to improve compression at a cost in speed because only one processor
at a time can be used on each block. I<zpaq> includes commands
for listing archives and extracting blocks in arbitrary
order to construct new archives without decompressing.

I<zpaq> contains speed optimizations for decompressing archives
compressed with the 4 built-in levels. The decompression algorithm
is described by a sandboxed, assembler-like, virtual machine
language called ZPAQL, which is normally interpreted. If an external
C++ compiler is installed, then I<zpaq> can improve decompression speed
of non built-in compression modes
by translating the ZPAQL to C++ and then compiling, running, and
deleting a temporary, optimized version of itself. This is
called just-in-time (JIT) optimization. It also performs JIT
optimization when compressing from a configuration file.
If this optimization fails (e.g. there is no external C++
compiler), then I<zpaq> falls back to interpreting
the ZPAQL, so its behavior is still correct. There are options
to skip this optimization or to save the temporary source or
executable, which may be useful for building new,
customized ZPAQ-compatible compressors.

A decompression algorithm has two parts: a context-mixing model
and an optional postprocessor. The model is the the same for
compression and decompression. It describes how to compute
the probability of data bits so that they can be arithmetic
coded or decoded. The postprocessor is optional. In general it is
different from the preprocessor. Only the postprocessor is stored
in the archive header. It is up to the user to supply an external
preprocessor program, which should perform the inverse operation on
the input data during compression. I<zpaq> normally tests the
postprocessor by verifying that it restores the original data
after preprocessing, and will refuse to compress if there is a
mismatch. There is an option to skip this test to save time
if you are sure that it works.
The first two (faster) built-in compression levels use built-in
preprocessors (without postprocessor testing).

For debugging configuration files, I<zpaq> can run or trace
the execution of context modeling or postprocessing code.
The code is run JIT-optimized by default. Tracing displays
instructions and virtual registers during execution and
memory contents when done.

=head1 COMMANDS

=over 4

=item B<a I<archive> I<file>...>

Compress the listed files and append them to I<archive>C<.zpaq>.
If I<archive> does not have a C<.zpaq> extension, then one is
added. File names are saved in the archive exactly as specified in
the command.

=item B<b I<archive> I<output> [N[-N]]...>

Append the listed blocks of I<archive>C<.zpaq> to
I<output>C<.zpaq>. The C<.zpaq> extension is added to
both file names if not present. The block list is a list
of positive integers or inclusive ranges of integers, where
1 is the first block. For example, C<zpaq in out 1 3-5>
appends the first, third, fourth, and fifth block of F<in.zpaq>
to F<out.zpaq>.

The listed blocks do not have to be in ascending
order and may be repeated. The effect of reordering blocks
is to reorder the data they represent after decompression.
If a block begins with unnamed file segments, then that data
is appended to the last named file upon decompression.

=item B<c I<archive> I<file>...>

Compress the listed files and create a new I<archive>C<.zpaq>.
The command is like B<a> except that if I<archive>C<.zpaq>
exists then it is overwritten rather than appended.

=item B<e I<archive> [I<files>...]>

Extract files from I<archive>C<.zpaq> in the order they were added,
creating or overwriting one file for each file listed in I<files>,
up to the number of files in the archive. The C<.zpaq> extension
is added to I<archive> if not present. If no I<files> are listed,
then the entire archive is extracted to the current directory
using the saved file names (ignoring any saved path). In this case,
output files that already exist will not be clobbered. If the
archive does not begin with a named file, then all data up to
the first named segment is assumed to have the name I<archive>
without the C<.zpaq> extension.

=item B<l I<archive>>

List I<archive>C<.zpaq> contents. There is one line per segment.
Each line shows the block number, first 8 hexadecimal digits of
the 40 digit SHA-1 checksum if present,
filename if present, comment (original size) if present, and
compressed size. If there is no filename then the segment is
a continuation of the previous file.
A summary shows the total original and compressed
sizes of the archive and the maximum memory required by any
block (for one thread) to decompress.

=item B<r [I<input> [I<output>]]>

Run the post-processor (PCOMP section) of the configuration
file specified by B<-m> as
a stand-alone program taking input from file I<input> (default
standard input) and writing to file I<output> (default
standard output). The code is executed once for each input byte
and once more with -1 (EOF) as input (simulating what happens
during decompression). The command is useful
mainly for testing and debugging configuration files.

=item B<t [N]...>

Trace the post-processor (PCOMP section) of the configuration
file specified by B<-m> once for each numeric argument B<N>
as input. As each ZPAQL instruction is executed, the instruction
and register contents are displayed on a single line. When the
program ends (executes HALT), the contents of any nonzero memory
is displayed. Numeric arguments can either be written in decimal
or hexadecimal with a leading "x" (as in C<255> or C<xff>).
The output is displayed in the same base as the input.
The command is useful for debugging configuration files.

=item B<x I<archive> [I<files>...]>

Extract from I<archive>C<.zpaq> like B<e>, except that the
stored path (not just the file name) is used if I<files>
are omitted. Directories are created
as needed. A saved path may use either forward slashes (/)
or backslashes (\) as directory separators. During extraction,
"/" is converted to "\" in Windows, and "\" to "/" in Linux.

=back

=head1 OPTIONS

=over 4

=item B<-b{N|s}>

During compression, split large files into blocks of size N MB.
B<-b0> means to compress
using one block per file. B<-bs> means to compress all of the
input files into one block (solid mode). For example, B<-b0.25>
specifies blocks of 250,000 bytes.

For compression levels B<-m1> and B<-m2>, the default block
size is B<-b16> or 16 MB. The largest block size allowed
is B<-b268.435199>. B<-b0>, B<-bs>, or any larger size will
automatically select this value. For levels B<-m3>,
B<-m4>, and configuration files, the default is B<-b0>.

=item B<-f>

Force overwrite of output files when extracting with B<e> or B<x>.

=item B<-h>

During compression (B<a> or B<c>), save a 13 byte header
locator tag at the start of the archive. The tag is only needed to
find the archive if it is appended to or embedded in non-ZPAQ data,
such as a self extracting archive stub.

With B<r> or B<t>, B<-h> means to run or trace the context computation
ZPAQL code (HCOMP section) of the configuration file specifed by
B<-m>, rather than the post-processing (PCOMP) code. With B<r>, do
not run with an extra EOF at the end of input.

=item B<-i>

During compression, do not save comments. Normally, I<zpaq>
saves file segment sizes as decimal strings which are displayed
when the archive is listed. This option saves a few bytes
but has no other effect.

=item B<-j{0|1|2|3}>

Control JIT (just in time) optimization. B<-j0> says that
when a non built-in compression level is detected, either
when compressing with or running a configuration file or when
decompressing, then interpret the ZPAQL code. The default
behavior, selected by B<-j1>, is to translate the ZPAQL code
to C++, attempt to compile it with an external compiler
(called by the script F<zpaqopt>), and run the resulting
program with the same arguments. This will usually run faster
than interpreting the ZPAQL code. If compilation fails
(because there is no C++ compiler or F<zpaqopt> script),
then the code is interpreted as with B<-j0>.  B<-j2> says
not to delete the temporary source code when the program is
finished. B<-j3> says not to delete the temporary executable either.

=item B<-m{1|2|3|4|I<config>[,N]...}>

Select compression level from B<-m1> (fastest) to B<-m4> (best),
or use a custom algorithm described in the configuration
file I<config>C<.cfg> with up to 9 comma-separated
numeric arguments. The default is B<-m1>. The following table
shows memory usage and equivalent configurations for the 4 built
in compression levels.

    Level  Config     Memory per thread  Algorithm
    -----  ------     -----------------  ---------
    -m1    -mbwtrle1  5x block*          BWT + RLE + CM1
    -m2    -mbwt2     5x block*          BWT + CM2
    -m3    -mmid      111 MB             CM8
    -m4    -mmax      246 MB             CM22
    *block size is rounded up to a power of 2

By default, B<-m1> and B<-m2> use 80 MB memory per thread because the
default block size is 16 MB.

=item B<-n>

Do not save file names during compression, or ignore
them during extraction. The result in either case is that all
of the compressed data is concatenated to a single file which
is named by default by dropping the C<.zpaq> extension from
the archive.

=item B<-p>

Do not save paths with filenames during compression, or ignore
them during extraction. The result in either case is that files
will be extracted to the current directory like B<e>.

=item B<-q>

Do not test the post-processor when compressing with a
configuration file that uses one. The default is to run the
preprocessed input (created with a user supplied preprocessor)
through the post-processor specified in the configuration file
and compare the SHA-1 checksum of the output with the original
input and refuse to compress if they do not match.

=item B<-s>

Do not save SHA-1 checksums during compression, or report but
do not exit with an error if a checksum mismatch is detected
during extraction. This saves 20 bytes per file or block.

=item B<-tN>

Use N threads during compression or decompression. The default
is the number of processors detected.
Using fewer threads can reduce memory usage but run slower.
Using more threads than processors does not run any faster.

=item B<-v>

Run verbosely. Show all steps, such as the creation, appending,
and deletion of temporary files when compressing or extracting
files split into blocks, when preprocessing with a configuration
file, or when using JIT optimization. During compression with
configuration files, memory usage per component is shown, which
is helpful when adjusting component sizes. Also, the configuation
file contents is displayed, which makes it easier to find syntax
errors. With B<l>, the saved configuration is displayed in
a format suitable for insertion into a configuration file.

=back

=head1 EXIT STATUS

Returns 0 if successful or 1 in case of an error.

=head1 EXAMPLES

Compress all of the files in directory F<calgary> to
archive F<calgary.zpaq> with maximum compression.

    zpaq -m4 c calgary calgary/*

List contents:

    zpaq l calgary

The contents are displayed with each file in a separate block:

    Block Checksum File Comment -> Compressed size for calgary.zpaq
    [  1] 3f86203a calgary/BIB 111261 -> 23006
    [  2] 673c583d calgary/BOOK1 768771 -> 199473
    [  3] b855cfaf calgary/BOOK2 610856 -> 128365
    [  4] 5cf652cf calgary/GEO 102400 -> 46593
    [  5] afd9f190 calgary/NEWS 377109 -> 96360
    [  6] d155a7f8 calgary/OBJ1 21504 -> 8933
    [  7] e02c588e calgary/OBJ2 246814 -> 56177
    [  8] aef6dac8 calgary/PAPER1 53161 -> 13939
    [  9] 93d9bf0d calgary/PAPER2 82199 -> 21357
    [ 10] 96f7ab3d calgary/PIC 513216 -> 28240
    [ 11] 66fa53f7 calgary/PROGC 39611 -> 10410
    [ 12] 7f972316 calgary/PROGL 71646 -> 12078
    [ 13] 22c59a40 calgary/PROGP 49379 -> 8408
    [ 14] 34322336 calgary/TRANS 93695 -> 13285
    Total 3141622 -> 666624. 246.227 MB memory per thread needed.

To extract to directory F<calgary>, overwriting existing files
if any, or creating the directory if needed:

    zpaq -f x calgary

To extract just F<BOOK1> to F<book.out>, create a temporary
archive containing only block 2:

    zpaq b calgary tmp 2
    zpaq x tmp book.out

=head1 CONFIGURATION FILES

=head2 Context Mixing Theory

All ZPAQ compliant programs use a configurable compression algorithm
based on the PAQ model of bitwise context modeling plus optional pre-
and post-processing. The ZPAQ standard defines the model precisely.

A model treats the data as a stream of bits which are predicted and
arithmetic coded one at a time. The compression ratio depends on the
accuracy of the predictions or probability assignments. When the next
bit is assigned a probability I<p> that it will be a 1, it means that
if the bit is actually 1, it will be coded at a cost of log2(1/p)
bits, and if it is a 0 it will be coded at a cost of log2(1/(1-p)).
ZPAQ codes bits in MSB (most significant bit) to LSB (least
significant bit) order, although either order would work.

During decompression, a model makes an identical series of predictions
based on the previously decoded output. Thus, the same model is used
for both compression and decompression, and only needs to be specified
once. This differs from preprocessing and postprocessing, which should
be inverses of each other. A ZPAQ archive only saves the
postprocessing code. It is up to the compressor to verify its
correctness.

ZPAQ (and PAQ) achieve a high compression ratio by using many
independent context models to estimate I<p> and then combining the
estimates by weighted averaging and possibly applying further
context-sensitive refinements. These components can be put together
like building blocks. Generally there is a 3 way tradeoff between
compression ratio, speed, and memory. Using more components usually
results in better compression but takes longer to execute. Allocating
more memory to components allows more statistics to be collected,
which improves compression.

A context model component takes a context as input and outputs a
prediction. After the predicted bit is learned, the model is adjusted
to reduce the prediction error. It is up to the model to select useful
contexts. For example, for text compression, the useful contexts are
order-n (the last n whole bytes) and the last whole word or two. For
images, a useful context might be the high order bits of some
neighboring pixels.

Compression can sometimes be improved by preprocessing and
postprocessing. For example, text can sometimes be compressed better
by using a dictionary to encode common words using 1 or 2 byte codes
before compression. The postprocessor would expand the codes back into
words. An image preprocessor might predict pixels using some weighted
average of earlier nearby pixels (perhaps dynamically tuning the
weights to reduce prediction errors) and then compress the differences
with a simple order-0 model. The postprocessor would make an identical
set of predictions and add them to the decompressed differences.

The user is responsible for making sure that preprocessing followed by
postprocessing will restore the original data exactly, but I<zpaq>
will still check before compressing.

=head3 Types of components

ZPAQ uses several component types. All of them take a context
as input and output a prediction. Some also take the outputs
of other components as inputs.

A simple context model (CM) computes a prediction by counting bits.
For example, a sequence "00001" in some context would assign p = about
1/5 (or more precisely, 1.5/6 by starting both counts at 0.5). The
prediction is achieved indirectly by starting with a prediction of p =
1/2 and a count of 0, and then adjusting p to reduce the error in
inverse proportion to the count.

However, such a prediction might not be correct because the bits in
the sequence might not be independent. A direct context map
effectively gives higher weights to more recent history (so p > 1/5)
by placing an upper bound on the count. A smaller bound makes the
model more adaptive, but could also make compression worse if the
input data has uniform statistics so that the bits really are
independent.

A more general solution is to use an indirect context model (ICM) to
predict based on what happened when the same bit sequence occurred in
other contexts. This is achieved by mapping a context to a bit history
table, and then mapping the bit history to a prediction. The bit
history is updated by appending the next bit, and the prediction is
updated to reduce the prediction error, usually at a small, constant
rate (like 0.001 times the error). To save space, the bit history is
represented as an 8 bit state representing a count, a ratio of zeros
to ones, and the value of the last bit. The count is bounded to a
small value. The initial prediction is set to the ratio.

A mixer takes a set of predictions from other components and combines
them by weighted averaging. On update, the mixer reduces its output
error by adjusting the weights to favor the input models that made
better predictions. Weighted averaging occurs in the logistic domain,
log(p/(1-p)), which gives greater weight to high confidence
predictions, which are those near 0 or 1. The initial weights for an
n-input mixer are 1/n.

It is sometimes advantageous to select from a set of weight vectors using a
low order context. Compression can often be improved further (at a
cost in speed) by using a hierarchy of mixers taking different
contexts.

A prediction from a mixer (or the last mixer in a hierarchy) can be
further refined using secondary symbol estimation (SSE). An SSE picks
the output prediction from an array of 32 simple context models (CM)
by interpolating between the two nearest quantized input prediction
values.

An indirect SSE (ISSE) works like an SSE except that it uses bit histories
as contexts like an ICM to save memory. This makes it appropriate for
higher order contexts. It is possible to model directly using a chain
of ISSE in increasing order starting with an order 0 CM or ICM as the
first component in the chain. Unline an SSE, an ISSE adjusts the input
probability by mixing it with a fixed constant using the bit history
to select the pair of mixing weights. Initially it assigns a weight of 1
to the input prediction and 0 to the constant.

A MATCH component predicts bits by looking for the most recent
occurrence of the current (usually high order) context and predicting
the next bit following the match. The weight of the prediction is
proportional to the length of the match, i.e. directly proportional in
the logistic domain, and negative if the predicted bit is 0. Matches
are found by saving past data in a history buffer and using a hash
table of pointers into the buffer indexed by a context hash. If no
match is found, then the prediction is 1/2, or 0 in the logistic
domain.

=head3 Context computation

ZPAQ uses a program written in a langauge called ZPAQL to
compute 32-bit contexts or context hashes and save them in an array.
Each array element then becomes the
context for one component. As a speed optimization, the program is called
only once per byte rather than once per bit, with the last data byte
as input. This means that the computed context must be combined
with the next 0 to 7 data bits. The method of combining the computed and bitwise contexts depends on the component. Generally, only the low
order bits of the context are used, depending on the size of the
component.

For indirect models (ICM and ISSE), bit histories are
stored in a hash table that is looked up on nibble (4 bit) boundaries.
Each table element contains an 8 bit checksum confirmation to detect
(most) hash collisions, and an array of 15 bytes representing bit
histories for each of the 15 bitwise contexts that result from
appending 0 to 3 more bits of context. Thus, the table is looked up
twice per byte. The first lookup uses the low bits of the computed
hash and the next higher 8 bits as a hash confirmation. The second
lookup adds 16 x (16 + nibble) to it. The hash table looks up 3
adjacent values within the same 64 byte cache line and uses least
frequeny used (LFU) replacement based on the count represented by the
nibble boundary bit history if a matching checksum is not found.

For a mixer or SSE, a 1 is appended to the beginning of the partial
byte context to create an 8 bit value, which is added to the computed
context. For example, if the first 5 bits of the current byte are
xxxxx, then the binary number 1xxxxx is added to the context to
predict the next bit.

For a CM, the bitwise context is expanded to a 9 bit value by
splitting it into two nibbles, appending a 1 bit to the partial low
nibble, and setting the first bit to indicate that the context
includes two nibbles. For example, xx is expanded to 0000001xx, and
xxxxxx is expanded to 1xxxx01xx. Then this context is XORed with the
computed context. This expansion reduces cache misses to improve speed
by causing four consecutive contexts to fall within the same 64 byte
cache line.

=head2 Config file format

The compression and decompression algorithm is described in a
configuration file, which must have a B<.cfg> extension. The
decompression algorithm is stored in the ZPAQ archive. The
configuration file is only needed during compression. It has 3 parts:

COMP - a description of a sequence of bit predictors. Each component
takes a context and earlier predictions as input, and outputs a
prediction for the next bit. The last component's prediction is output
to the arithmetic coder.

HCOMP - a program that is called once for each byte of uncompressed
data with that byte as input, and outputs an array of 32-bit contexts,
one for each component in the COMP section. The program is written in
ZPAQL.

POST/PCOMP - an optional pair of programs to preprocess the input
before compression and postprocess the output after decoding for
decompression. POST indicates no pre- or postprocessing. The model
described by COMP and HCOMP sees a 0 byte followed by a concatenation
of the uncompressed files. During decompression, the leading 0
indicates no postprocessing.

PCOMP describes an external program to preprocess the input files
during compression, and a ZPAQL program to perform the reverse
conversion to restore the original input. The compression model
described in the COMP and HCOMP sections sees a 1 as the first byte to
indicate that the decoded data should be postprocessed before output.
This is followed by a 2 byte program length (LSB first), the ZPAQL
postprocessor code, and a concatenation of the preprocessed input
files. The PCOMP code sees just the preprocessed files as input, each
ending with EOS (-1).

The preprocessor is an external program. It is not needed for
decompression so it is not saved in the archive. It expects to be
called with an input filename and output filename as its last 2
arguments.

The postprocessor is a ZPAQL program that is called once for each
input byte and once with input EOS (-1) at the end of each segment.
The program is initialized at the beginning of a block but maintains
state information between segments within the same block. Its input is
from a temporary file created by the preprocessor during
compression testing and from the decoder during decompression.

The configuration file has the following format:

    COMP hh hm ph pm n
      (n numbered component descriptions)
    HCOMP
      (program to generate contexts, memory size = hh, hm)
    POST (for no pre/post procesing)
      0
    END

Or (for custom pre/post processing):

    COMP hh hm ph pm n
      (...)
    HCOMP
      (...)
    PCOMP preprocessor-command ;
      (postprocessor program, memory size = ph, pm)
    END

Configuration files are free format (all white space is the same) and
mostly not case sensitive. They may contain comments in ((nested)
parenthesis).

=head2 Components

The COMP section has 5 arguments (hh, hm, ph, pm, n) followed by a
list of n components numbered consecutively from 0 through n-1. hh,
hm, ph, and pm describe the sizes of the arrays used by the HCOMP and
PCOMP virtual machines as described later. Each machine has two
arrays, H and M. Their sizes are 2^hh and 2^hm respectively in HCOMP,
and 2^ph and 2^pm in PCOMP. The HCOMP program computes the context for
the n components by placing them in H[0] through H[n-1] as 32-bit
numbers. Thus, hh should be set so that 2^hh >= n. For
example, in mid.cfg, there are n = 8 components, so
hh = 3, allowing up to 8 contexts. Larger values would work but
waste memory. Memory usage is 2^(hh+2) + 2^hm + 2^(ph+2) + 2^pm bytes.

Each component outputs a "stretched" probability in the form
ln(p(1)/p(0)). where p(1) and p(0) are the model's estimated
probabilities that the next bit will be a 1 or 0, respectively. Thus,
negative numbers predict a 0 and positive predict 1. The magnitude is
the confidence of the prediction. The output is a number in the range
-32 to 32 with precision 1/64 (a 12 bit signed number).

The 9 possible component types are shown below. All component
parameters are numbers in the range 0..255. The component numbers I<i>
must be consecutive from 0 to n-1.

=over

=item I<i> CONST I<c> (constant)

Output is a constant (I<c>-128)/16. Thus, numbers larger than 128
predict 1 and smaller predict 0, regardless of context. CONST is very
fast and uses no memory.

=item I<i> CM I<s> I<limit> (context model)

Outputs a prediction by looking up the context in a table of size 2^s
using the s low bits of the H[i] (for component i) XORed with a 9 bit
expansion of the previously coded (high order) bits of the current
byte. (Recall that H[i] is updated once per byte). Each table entry
contains a prediction p(1) and a count in the range 0..I<limit>*4 (max
1020). The prediction is updated in proportion to the prediction error
and inversely proportional to the count. A large limit (max 255) is
best for stationary sources. A smaller value makes the model more
adaptive to changing statistics. Memory usage is 2^(s+2) bytes.

=item I<i> ICM I<s> (indirect context model)

Outputs a prediction by looking up the context in a hash table of size
64 * 2^s bit histores (1 byte states). The histories index a second
table of size 256 that outputs a prediction. The table is updated by
adjusting the prediction to reduce the prediction error (at a slow,
fixed rate) and updating the bit history. The hash table is indexed by
the low s+10 bits of H[i] and the previous bits of the current byte,
with highest 8 bits (s+9..s+2) used to detect hash collisions. An ICM
works best on nonstationary sources or where memory efficiency is
important. It uses 2^(s+6) bytes.

=item I<i> MATCH I<s> I<b>

Outputs a prediction by searching for the previous occurrence of the
current context in a history buffer of size 2^b bytes, and predicting
whatever bit came next, with a confidence proportional to the length
of the match. Matches are found using an index of 2^s pointers into
the history buffer, each of which points to the previous occurrence of
the current context. A MATCH is useful for any data that has repeat
occurrences of strings longer than about 6-8 bytes within a window of
size 2^b. Generally, larger b (up to the file size) gives better
compression, and s = b-2 gives adequate indexing. The context should
be a high order hash. Memory usage is 4*2^s + 2^b bytes.

=item I<i> AVG I<j> I<k> I<wt> (fixed weight 2 input mixer)

Averages the predictions of components j and k (which must precede i,
the current component). The average is weighted by I<wt>/256 for
component j and 1 - I<wt>/256 for component k. Often, averaging two
predictions gives better results than either prediction by itself. wt
should be selected to favor the more accurate component. AVG is very
fast and uses no memory.

=item I<i> MIX2 I<s> I<j> I<k> I<rate> I<mask> (2 input mixer)

Averages the predictions of components j and k (which must precede i,
the current component) adaptively. The weight is selected from a table
of size 2^s by the low s bits of H[i] added to the masked, previously
coded bits of the current byte (an 8 bit value). A I<mask> of 255
includes the current byte, and a mask of 0 excludes it. (Other masks
are rarely useful). The adaptation I<rate> is selectable. Typical
values are around 8 to 32. Lower values are best for stationary
sources. Higher rates are more adaptive. A MIX2 generally gives better
compression than AVG but at a cost in speed and memory. Uses 2^(s+1)
bytes of memory.

=item I<i> MIX I<s> I<j> I<m> I<rate> I<mask> (m-input mixer)

A MIX works like a MIX2 but with m inputs over a range of components
j..j+m-1, all of which must precede i. A typical use is as the final
component, taking all other components as input with a low order
context. A MIX with 2 inputs is different than a MIX2 in that the
weights are not constrained to add to 1. This sometimes gives better
compression, sometimes worse. Memory usage is m*2^(s+2) bytes.
Execution time is proportional to m.

=item I<i> ISSE s j (indirect secondary symbol estimator)

An ISSE takes a prediction and a context as input and outputs an
adjusted prediction. The low s+10 bits of H[i] and the previous bits
of the current byte index a hash table of size 2^(s+6) bit histories
as with an ICM. The bit history is used as an 8 bit context to select
a pair of weights for a 2 input MIX (not a MIX2) with component j
(preceding i) as one input and a CONST 144 as the other. The effect is
to adjust the previous prediction using a (typically longer) context.
A typical use is a chain of ISSE after a low order CM or ICM working
up to higher order contexts as in mid.cfg. (This architecture is also
used in the PAQ9A compressor). Uses 2^(s+6) bytes.

=item I<i> SSE I<s> I<j> I<start> I<limit> (secondary symbol estimator)

An SSE takes a predicion and context as input (like an ISSE) and
outputs an adjusted prediction. The mapping is direct, however. The
input from component j and the context are mapped to a 2^s by 64 CM
table by quantizing the prediction to 64 levels and interpolating
between the two nearest values. The context is formed by adding the
partial current byte to the low s bits of H[i]. The table is updated
in proportion to the prediction error and inversely proportional to a
count as with a CM. The count is initialized to I<start> and has the
range (I<start>..I<limit>*4). A large limit is best for stationary
sources. A smaller limit is more adaptive. The starting count does not
start at 0 because the table is initialized so that output predictions
are the same as input predictions regardless of context. If the
initial guess is close, then a higher start value works better.

An SSE sometimes gives better compression than an ISSE, especially on
stationary sources where a CM works better than an ICM. But it uses
2^12 times more memory for the same context size, so it is useful
mostly for low order contexts. A typical use is to adjust the output
of a MIX. It is sometimes followed by an AVG to average its input and
output, typically weighted 75% to 90% in favor of the output.
Sometimes more than one SSE or SSE-AVG pair is used in series with
progressively higher order contexts, or may be used in parallel and
mixed. An SSE uses 2^(s+8) bytes.

=back

All components are designed to work with context hashes that are
uniformly distributed over the low order bits (depending on the s
parameter for that component). A CM, MIX2, MIX, or SSE may also be
used effectively with direct context lookup for low orders. In this
case, the low 9 bits of a CM or low 8 bits of the other components
should be cleared to leave space to combine with the bits of the
current byte. This is summarized:

    Component              Context size    Memory
    -------------------    ------------    ------
    CONST c                0               0
    CM s limit             s               2^(s+2)
    ICM s                  s+10            2^(s+6)
    MATCH s b              s               2^(s+2) + 2^b
    AVG j k wt             0               0
    MIX2 s j k rate mask   s               2^(s+1)
    MIX s j m rate mask    s               m*2^(s+2)
    ISSE s j               s+10            2^(s+6)
    SSE s j start limit    s               2^(s+8)

Although the ZPAQ standard does not specify a maximum for s, this
program will not create arrays 2GB (2^31) or larger when compiled
for 32 bit operating systems.

=head2 ZPAQL

There are one or two ZPAQL programs in a configuration file. The
first, HCOMP, describes a program that computes the context hashes.
The second, PCOMP, is optional. It describes the code that inverts any
preprocessing performed by an external program prior to compression.
The COMP and HCOMP sections are stored in the block headers
uncompressed. PCOMP, if used, is appended to the start of the input
data and compressed along with it.

Each virtual machine has the following state:

    4 general purpose 32 bit registers, A, B, C, D.
    A 1 bit flag register F.
    A 16 bit program counter, PC.
    256 32-bit registers R0 through R255.
    An array of 32 bit elements, H, of size 2^hh (HCOMP) or 2^ph (PCOMP).
    An array of 8 bit elements, M, of size 2^hm (HCOMP) or 2^pm (PCOMP).

Recall that the first line of a configuration file is:

    COMP hh hm ph pm n

HCOMP is called once per byte of input to be compressed or
decompressed with that byte in the A register. It returns with context
hashes for the n components in H[0] through H[n-1].

PCOMP is called once per decompressed byte with that byte in the A
register. At the end of a segment, it is called with EOS (-1) in A.
Output is by the OUT instruction. The output should be the
uncompressed data exactly as it was originally input prior to
preprocessing. H has no special meaning.

All state variables are initialized to 0 at the beginning of a block.
State is maintained between calls (and across segment boundaries)
except for A (used for input) and PC, which is reset to 0 (the first
instruction).

The A register is used as the destination of most arithmetic or
logical operations. B and C may be used as pointers into M. D points
into H. F stores the result of comparisons and is used to decide
conditional jumps. R0 through R255 are used for auxilary storage. All
operations are modulo 2^32. All array index operations are modulo the
size of the array (i.e. using the low bits of the pointer). The
instruction set is as follows:

    - Y=Z (assignment)
      - where Y is A B C D *B *C *D
      - where Z is A B C D *B *C *D (0...255)
    - AxZ (binary operations)
      - where x is += -= *= /= %= &= &~ |= ^= <<= >>= == < >
      - where Z is as above.
    - Yx (unary operations)
      - where Y is as above
      - where x is <>A ++ -- ! =0
      - except A<>A is not valid.
    - J N (conditional jumps)
      - where J is JT JF JMP
      - where N is a number in (-128...127).
    - LJ NN (long jump)
      - where NN is in (0...65535).
    - X=R N (read R array)
      - where X is A B C D
      - where N is in (0...255).
    - R=A N (write R array)
      - where N is in (0...255).
    - ERROR
    - HALT
    - OUT
    - HASH
    - HASHD

All instructions except LJ are 1 or 2 bytes, where the second byte is
a number in the range 0..255 (-128..127 for jumps). A 2 byte
instruction must be written as 2 tokens separated by a space, e.g. "A=
3", not "A=3" or "A = 3". The exception is assigning 0, which has a 1
byte form, "A=0".

The notation *B, *C, and *D mean M[B], M[C], and H[D] respectively,
modulo the array sizes. For example "*B=*D" assigns M[B]=H[D]
(discarding the high 24 bits of H[D] because M[B] is a byte).

Binary operations always put the result in A.

+=, -=, *=, &=, |=, ^=, = have the same meanings as in C/C++.

/=, %= have the result 0 if the right operand is 0.

A&~B means A &= ~B;

AE<lt>E<lt>=B, A>>=B mean the same as in C/C++ but are explicitly
defined when B > 31 to mean the low 5 bits of B.

E<lt>, >, == compare and put the result in F as 1 (true) or 0 (false).
Comparison is unsigned. Thus PCOMP would test for EOS (-1) as "A>
255". There are no !=, <=, or <= operators.

BE<lt>>A means swap B with A. A must be the right operand. "AE<lt>>B"
is not valid. When 32 and 8 bit values are swapped as in "*BE<lt>>A",
the high bits are unchanged.

++ and -- increment and decrement as in C/C++ but must be written in
postfix form. "++A" is not valid. Note that "*B++" increments *B, not
B.

! means to complement all bits. Thus, "A!" means A = ~A;

JT (jump if true), JF (jump if false), and JMP (jump) operands are
relative to the next instruction in the range -128..127. Thus "A> 255
JT 1 A++" increments A not to exceed 256. A jump outside the range of
the program is a run time error.

LJ is a long jump. It is 3 bytes but the operand is written as a
number in the range 0..65535 but not exceeding the size of the
program. Thus, "A> 255 JT 3 LJ 0" jumps to the beginning of the
program if A <= 255.

The R registers can only be read or written, as in "R=A 3 B=R 3" which
assigns A to R3, then R3 to B. These registers can only be assigned
from A or to A, B, C, or D.

ERROR causes an error like an undefined instruction, but is not
reserved for future use (possibly in ZPAQ level 2) like other
undefined instructions.

HALT causes the program to end (and compression to resume). A program
should always execute HALT.

OUT in PCOMP outputs the low 8 bits of A as one byte to the file being
extracted. In HCOMP it has no effect.

HASH is equivalent to A = (A + *B + 512) * 773; HASHD is equivalent to
*D = (*D + A + 512) * 773; These are convenient for computing context
hashes that work well with the COMP components. They are not required,
however. For example, "A+=*D A*= 12 *D=A" updates a rolling order s/2
context hash for an s-bit wide component pointed to by D. In general,
an order ceil(s/k) hash can be updated by using a multiplier which is
an odd multiple of 2^k. HASH and HASHD are not rolling hashes. They
must be computed completely for each context. HASH is convenient when
M is used as a history buffer.

In most programs it is not necessary to code jump instructions. ZPAQL
supports the following structured programming constructs:

    IF ... ENDIF              (execute ... if F is true)
    IF ... ELSE ... ENDIF     (execute 1st part if true, 2nd if false)
    IFNOT ... ENDIF           (execute ... if F is false)
    IFNOT ... ELSE ... ENDIF  (execute 1st part if false, 2nd if true)
    DO ... WHILE              (loop while true (test F at end))
    DO ... UNTIL              (loop while false)
    DO ... FOREVER            (loop forever)

These constructs may be nested 1000 deep. However IF statements and DO
loops nest independently and may be crossed. For example, the
following loop outputs a 0 terminated string pointed to by *B by
breaking out when it finds a 0. The construct DO IF...FOREVER ENDIF
is equivalent to a "while" loop.

    DO
      A=*B A> 0 IF (JF endif)
	OUT B++
      FOREVER (JMP do)
    ENDIF

IF, IFNOT, and ELSE are coded as JF, JT and JMP respectively. They can
only jump over at most 127 instructions. If the code in these sections
are longer, then use the long forms IFL, IFNOTL, or ELSEL. These
behave the same but are coded using LJ instead. There are no special
forms for WHILE, UNTIL, or FOREVER. The compiler will automatically
use the long forms when needed.

=head2 Parameters

In a config file, paramaters may be passed as $1, $2, ..., $9. These
are replaced with numeric values passed on the command line. For
example, C<-mmax,3,4> would have the effect of
replacing $1 with 3 and $2 with 4. The default value is 0, i.e. $3
through $9 are replaced with 0.

In addition, a parameter may have the form $N+M, where N is 1 through
9 and M is a number. The effect is to add M. For example, $2+10 would
be replaced with 14. Parameters may be used anywhere in the config
file where a number is allowed.

=head2 Pre/Post processing

The PCOMP/POST section has the form:

    POST 0 END

to indicate no preprocessing or postprocessing, or

    PCOMP preprocessor-command ;
      (postprocessing code)
    END

to preprocess with an external program and to invert the transform
with postprocessing code written in ZPAQL. The preprocessing command
must end with a space followed by a semicolon. The command may contain
spaces or options. The program is expected to take as two additional
arguments an input file and an output file. ZPAQ will call the program
by passing it the input file and a temporary file.
Then it will (unless prevented by B<-q>) run the temporary file through
the postprocessing code and verify that its SHA-1 checksum matches the
input. If so, then it compresses the temporary file in a second pass.
If the input file is divided into blocks, then the program will
create temporary files of the appropriate sizes and pass them to
the preprocessor.

=head1 COMPRESSION ALGORITHMS

The four built-in compression levels B<-m1> through B<-m4>
have corresponding configuration files F<bwtrle1.cfg>,
F<bwt2.cfg>, F<mid.cfg>, and F<max.cfg> respectively, shown
below.

=over

=item B<-m1>

B<bwtrle1> preprocesses the input using a Burrows-Wheeler transform
(BWT) followed by run length encoding (RLE). A BWT divides the input
into blocks (with size selected by B<-b>), appends an EOF (-1),
and sorts the characters by their right context. This transform
brings together bytes with similar contexts, so it tends to produce
long runs of identical values which are easily compressed. The BWT
is reversible as long as the location of the EOF symbol is known.
Because -1 cannot be stored as a byte, it is replaced with a 255
and its location is appended to the end as a 4 byte little-endian
(LSB first) index. The stream is then RLE encoding, such that
sequences of 2 to 257 identical bytes are replaced with the first
two bytes and a count of the remaining bytes. Next, the encoded
stream is compressed with an order 0 ICM which uses the RLE state
(literal or count) as context.

The code below takes one argument to control the block size.
I<zpaq> generates code that effectively selects the argument B<$1>
to choose the smallest block (least memory) possible. The block
size must be a power of 2 and at least 257 bytes larger than
the input size. It calls the external program F<bwtrle> to
perform the BWT and RLE encoding.

The HCOMP section computes the RLE state and stores it in H[0]
as context to the ICM. The code is called with the current input
byte in A.  D is initialized to 0 so it always points
to H[0]. C contains the previous input byte. B contains the
RLE state, a count of how many times the last two bytes were
the same. If B is 2, then A contains a count. If B is 0 or 1
then it contains a literal. The last line of code before HALT
stores a hash of B in H[0]. During modeling, the leading bits
of the current byte are added to this hash to compute the
context.

The PCOMP section receives decoded bytes and a final EOF (-1)
in A. Before the EOF, it receives each byte, expands runs,
and stores the result in the M array. It uses B as a pointer
to the next byte in M to be written, and C as a temporary copy
of the input byte. It uses D as the RLE state. It is initially
0. After the first byte, it is set to A+1 (1..256). If the second
byte is a match, then it is set to A+257 (257..512) to indicate
that a count is expected next. When the count is received, D-257
is stored the indicated number of times.

When EOF is input (A>255 as an unsigned), the program computes
the inverse BWT and outputs it. The generic inverse BWT algorithm
of buf[0..n-1], buf[idx]==EOF outputs n-1 bytes (no EOF) as follows:

    unsigned char buf[n];  // input BWT
    unsigned int idx;      // input location of EOF in BWT
    FILE* out;             // output
    unsigned int count[256]={0};  // Cumulative byte counts
    unsigned int list[n]={0}      // Circular linked list

    // Count bytes
    for (size_t i=0; i<n; ++i)
      ++count[(buf[i]+1)&255];

    // Cumulative counts including EOF
    count[0]=1;
    for (size_t i=1; i<256; ++i)
      count[i]+=count[i-1];

    // Build linked list including EOF at idx
    for (size_t i=0; i<idx; ++i)
      list[count[buf[i]]++]=i;
    for (size_t i=idx+1; i<n; ++i)
      list[count[buf[i]]++]=i;

    // Scan linked list and output n-1 bytes
    for (size_t p=idx; p;) {
      p=list[p];
      putc(buf[p], out);
    }

In the equivalent ZPAQL code, buf[0..n-1] and idx are appended
in M with b == n+4. The first section reads idx into C and R1
and leaves n in B and R2. The next two loops store the cumulative
byte counts in the last 257 elements of H in reverse order
(H[-1..-256]). The remaining elements of H are used for
the linked list. The list has to be built in 2 parts because
buf[idx] contains 255 rather than -1. The final loop outputs
n-1 bytes.

    (BWT + RLE + order 0 model.
    Requires 80 MiB memory for files up to 16 MiB - 257 bytes.
    Use argument 1 to double, -1 to halve)
    comp 1 0 $1+24 $1+24 1
      0 icm 7
    hcomp
      a==c c=a if
        b++
      else
        b=0
      endif
      a=b *d=0 hashd
      halt
    pcomp bwtrle e ;

      (read BWT and index into M[0..b-1] with RLE decoding:
       X X n -> n+2 copies of X)
      a> 255 ifnot
        c=a (copy of input byte)
        a=d a== 0 if (d=0 = initial RLE state: write c and save c+1 in d)
          d=c d++
          *b=c b++
        else
          a=d a-- a> 255 ifnot (d=1..256 = last byte + 1)
            a==c if
              a+= 255 a++ a++ d=a (d=257..512 = RLE count is next)
            else
              d=c d++
            endif
            *b=c b++
          else (d=257..512 = write c repeats of d-257)
            d--
            do a=c a> 0 if
              *b=d b++ c--
            forever endif
            d=0 (reset RLE state)
          endif
        endif

      (inverse BWT)
      else
	
        (index in last 4 bytes, put in c and R1)
        b-- a=*b
        b-- a<<= 8 a+=*b
        b-- a<<= 8 a+=*b
        b-- a<<= 8 a+=*b c=a r=a 1

        (save size in R2)
        a=b r=a 2

        (count bytes in H[~1..~255, ~0])
        do
          a=b a> 0 if
            b-- a=*b a++ a&= 255 d=a d! *d++
          forever
        endif

        (cumulative counts: H[~i=0..255] = count of bytes before i)
        d=0 d! *d= 1 a=0
        do
          a+=*d *d=a d--
        d<>a a! a> 255 a! d<>a until

        (build first part of linked list in H[0..idx-1])
        b=0 do
          a=c a>b if
            d=*b d! *d++ d=*d d-- *d=b
          b++ forever
        endif

        (rest of list in H[idx+1..n-1])
        b=c b++ c=r 2 do
          a=c a>b if
            d=*b d! *d++ d=*d d-- *d=b
          b++ forever
        endif

        (traverse list and output)
        d=r 1 do
          a=d a== 0 ifnot
            d=*d
            b=d a=*b out
          forever
        endif
      endif
      halt
    end

=item B<-m2>

B<bwt2> works like B<bwtrle1> except that the RLE step is skipped
and the context model has two components. These both improve
compression at a cost in speed. The order 0 ICM output
is refined through an order 1 ISSE for better compression.
In the code below, the inverse BWT is identical in the POST
section, but the RLE decoding prior to EOF is omitted. The
HCOMP section does not compute any context for component 0
(because there is no RLE state) but uses the current byte
for component 1.

    comp 1 0 $1+24 $1+24 2
      0 icm 5
      1 isse 12 0
    hcomp
      d= 1 *d=0 hashd halt
    pcomp bwtrle c ;
    
      (read BWT, index into M, size in b)
      a> 255 ifnot
        *b=a b++
    
      (inverse BWT)
      else
    
        (index in last 4 bytes, put in c and R1)
        b-- a=*b
        b-- a<<= 8 a+=*b
        b-- a<<= 8 a+=*b
        b-- a<<= 8 a+=*b c=a r=a 1
    
        (save size in R2)
        a=b r=a 2
    
        (count bytes in H[~1..~255, ~0])
        do
          a=b a> 0 if
            b-- a=*b a++ a&= 255 d=a d! *d++
          forever
        endif
    
        (cumulative counts: H[~i=0..255] = count of bytes before i)
        d=0 d! *d= 1 a=0
        do
          a+=*d *d=a d--
        d<>a a! a> 255 a! d<>a until
    
        (build first part of linked list in H[0..idx-1])
        b=0 do
          a=c a>b if
            d=*b d! *d++ d=*d d-- *d=b
          b++ forever
        endif
    
        (rest of list in H[idx+1..n-1])
        b=c b++ c=r 2 do
          a=c a>b if
            d=*b d! *d++ d=*d d-- *d=b
          b++ forever
        endif
    
        (traverse list and output)
        d=r 1 do
          a=d a== 0 ifnot
            d=*d
            b=d a=*b out
          forever
        endif
      endif
      halt
    end

=item B<-m3>

B<mid> uses no pre/post processing. It has 8 components:
an order 0 through 5 ICM-ISSE chain, an order
7 MATCH, and a final order 1 mixer that combines all 7 other
predictions. In the code, M is used as a rotating bufer
containing the last 8 input bytes and C points to the
head of the buffer. The code computes hashes of context
orders 0, 1, 2, 3, 4, 5, 7, 1 and puts them in D[0..7] for
those respective components. The mixer takes a 16 bit
order-1 context which is not hashed. The last byte
is placed in the high order bits and the leading bits
of the current byte are placed in the 8 low order bits.

The order 0-5 ICM-ISSE chain components use increasingly
large hash tables up to 2^(19+6) = 32 MiB memory for
component 5. Each takes its input from the previous component.
The MATCH uses an index of size 2^22 pointers and a buffer
of size 2^24, which use 16 MiB each. The MIX has a 16 bit
context, takes 7 inputs starting at component 0, a learning
rate of 24, and a mask of 255 (no mask).

    comp 3 3 0 0 8 (hh hm ph pm n)
      0 icm 5        (order 0...5 chain)
      1 isse 13 0
      2 isse 17 1
      3 isse 18 2
      4 isse 18 3
      5 isse 19 4
      6 match 22 24  (order 7)
      7 mix 16 0 7 24 255  (order 1)
    hcomp
      c++ *c=a b=c a=0 (save in rotating buffer M)
      d= 1 hash *d=a   (orders 1...5 for isse)
      b-- d++ hash *d=a
      b-- d++ hash *d=a
      b-- d++ hash *d=a
      b-- d++ hash *d=a
      b-- d++ hash b-- hash *d=a (order 7 for match)
      d++ a=*c a<<= 8 *d=a       (order 1 for mix)
      halt
    post
      0
    end

=item B<-m4>

B<max> has 22 components. It has an order 0..5, 7 ICM-ISSE chain for
general purpose compression, a MATCH, a whole word order 0-1 ICM-ISSE
chain for modeling text, three order 1 ICM sparse models with gaps of
1 to 3 bytes, one ICM with a gap of 216 (one scan line) for modeling
binary FAX images, and one fixed prediction for mixer bias. The two
word contexts compute hashes of whole words by considering only
sequences of the letters B<a> through B<z>, ignoring case. These
predictions are mixed with a hierarchy of 3 mixers: one order 0, one
order 1, and one context free 2 input mixer to combine them. This
prediction is passed through two SSE stages (order 0 and 1) with an
order 0 mixer and a context free mixer of the SSE inputs and outputs
to allow the SSE to be partially bypassed adaptively. It does not
use pre/post processing.

    comp 5 9 0 0 22 (hh hm ph pm n)
      0 const 160
      1 icm 5  (orders 0-6)
      2 isse 13 1 (sizebits j)
      3 isse 16 2
      4 isse 18 3
      5 isse 19 4
      6 isse 19 5
      7 isse 20 6
      8 match 22 $1+24
      9 icm 17 (order 0 word)
      10 isse 19 9 (order 1 word)
      11 icm 13 (sparse with gaps 1-3)
      12 icm 13
      13 icm 13
      14 icm 14 (pic)
      15 mix 16 0 15 24 255 (mix orders 1 and 0)
      16 mix 8 0 16 10 255 (including last mixer)
      17 mix2 0 15 16 24 0
      18 sse 8 17 32 255 (order 0)
      19 mix2 8 17 18 16 255
      20 sse 16 19 32 255 (order 1)
      21 mix2 0 19 20 16 0
    hcomp
      c++ *c=a b=c a=0 (save in rotating buffer)
      d= 2 hash *d=a b-- (orders 1,2,3,4,5,7)
      d++ hash *d=a b--
      d++ hash *d=a b--
      d++ hash *d=a b--
      d++ hash *d=a b--
      d++ hash b-- hash *d=a b--
      d++ hash *d=a b-- (match, order 8)
      d++ a=*c a&~ 32 (lowercase words)
      a> 64 if
        a< 91 if (if a-z)
          d++ hashd d-- (update order 1 word hash)
          *d<>a a+=*d a*= 20 *d=a (order 0 word hash)
          jmp 9
        endif
      endif
      (else not a letter)
        a=*d a== 0 ifnot (move word order 0 to 1)
          d++ *d=a d--
        endif
        *d=0  (clear order 0 word hash)
      (end else)
      d++
      d++ b=c b-- a=0 hash *d=a (sparse 2)
      d++ b-- a=0 hash *d=a (sparse 3)
      d++ b-- a=0 hash *d=a (sparse 4)
      d++ a=b a-= 212 b=a a=0 hash
        *d=a b<>a a-= 216 b<>a a=*b a&= 60 hashd (pic)
      d++ a=*c a<<= 9 *d=a (mix)
      d++
      d++
      d++ d++
      d++ *d=a (sse)
      halt
    post
      0
    end

=back

=head1 ENVIRONMENT

Temporary files are placed in TEMP if defined, or else in TMPDIR
if defined, or else in F</tmp>.

In Windows, the default number of threads (set by B<-t>) is
NUMBER_OF_PROCESSORS. In Linux, the number of lines of the
form "Processor : 0", "Processor : 1",... in F</cpu/procinfo>
is used instead.

=head1 FILES

The script or program F<zpaqopt> (F<zpaqopt.bat>
in Windows) is required for JIT optimization and should be
somewhere in the current PATH. It should
compile C<$1.cpp> to C<$1.exe> where I<$1> is passed as
an argument. It needs to include F<libzpaq.h> and be linked to
the files F<zpaq.o> and F<libzpaq.o> which are prepared from
the source distribution as follows:

    g++ -O3 -DNDEBUG -DOPT -c zpaq.cpp libzpaq.cpp

These files may be placed anywhere, as long as F<zpaqopt> knows
where to find them. A possible installation for Windows,
assuming that %PATH% contains F<c:\bin> and that MinGW g++
is installed is:

    c:\bin\zpaq.exe
    c:\bin\zpaqopt.bat
    c:\zpaq\zpaq.o
    c:\zpaq\libzpaq.o
    c:\zpaq\libzpaq.h

F<zpaqopt.bat> would contain:

    g++ -O3 -DNDEBUG %1.cpp c:\zpaq\zpaq.o c:\zpaq\libzpaq.o -Ic:\zpaq -o %1.exe

A possible Linux installation might be

    /usr/bin/zpaq
    /usr/bin/libzpaq
    /usr/lib/zpaq/zpaq.o
    /usr/lib/zpaq/libzpaq.o
    /usr/include/libzpaq.h

zpaqopt would be a script:

    g++ -O3 -DNDEBUG %1.cpp -lpthread $1.cpp /usr/lib/zpaq/zpaq.o \
    /usr/lib/zpaq/libzpaq.o -o $1.exe

The script can be configured to use other optimization options
(like C<-s -march=native>), other compilers, or other installation directories as appropriate.
-DNDEBUG turns off run time checks. -DOPT prepares a different
version of I<zpaq> than this program, removing built-in optimizations
and other unneeded code.

=head1 STANDARDS

See the ZPAQ level 1 specification in section AVAILABILITY . It is
anticipated that future levels (ZPAQ-2, ZPAQ-3, etc.) will be backward
compatible, such that newer levels can read archives produced by older
programs.

=head1 AVAILABILITY

http://mattmahoney.net/dc/zpaq.html

=head1 BUGS

There is no GUI.

Recursive directory compression is not supported.

Timestamps and other file attributes are not preserved. If you need this,
make a B<.tar.zpaq> file.

A file may be appended to an archive more than once.
Extraction of subsequent
copies will fail without renaming on the command line.

Temporary files might not be deleted if the program is interrupted
or if an error occurs.
Temporary files have the form F<zpaqtmp*> in the temporary directory.

ZPAQL is not very user friendly as a language.

=head1 SEE ALSO

See especially lrzip(1) which uses ZPAQ algorithm (although in
an incompatible archive format).

C<bzip2(1)>
C<gzip(1)>
C<lrzip(1)>
C<lzop(1)>
C<lzma(1)>
C<p7zip(1)>
C<rzip(1)>
C<unace(1)>
C<unrar(1)>
C<unzip(1)>
C<unzaq(1)>
C<zip(1)>
C<libzpaq(3)>

=head1 AUTHORS

I<zpaq> uses code from I<libzpaq> v3.00 and I<libdivsufsort-lite> v2.01.

I<zpaq> v3.01 is copyright (C) 2011, Dell Inc. It is written by Matt
Mahoney. It is licensed under GPL v3, or at your option,
any later version. For information on
the license, see <http://www.gnu.org/copyleft/gpl.html>.
Program was written by Matt Mahoney <matmahoney@yahoo.com>.

I<libzpaq> v3.00 is copyright (C) 2011, Dell Inc. It is written
by Matt Mahoney. It is licensed
under a modified MIT license allowing unrestricted use. See
the source code for license text.

I<libdivsufsort-lite> v2.01 is copyright (C) 2003-2008,
Yuta Mori. It is licensed under the MIT license. See the source
code for license text.

=cut

